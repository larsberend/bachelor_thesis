\documentclass[Bachelorarbeit.tex]{subfiles}
\begin{document}

\newpage
\begin{center}
\textbf{Abstract}
\end{center}

In this thesis, various approaches for generating motion descriptors are evaluated, including pixel-based methods, i.e. SSIM and dense optical flow, and feature-based methods using algorithms like Lucas-Kanade, Gabor or Pyramid Histograms of Oriented Gradients. This thesis will provide the basis for the identification of eye movements in videos without previous calculations of gaze and a 3d model of the eye, since they are costly and not easy to come by. 
Approaches to find features in eye tracking videos are compared qualitatively, with a main focus on three properties. First, the quantity and distribution of features over time is calculated and compared. Second, the semantical relevance of features is evaluated, i.e. if features are positioned at the edge of the pupil or eyelids. Third, the robustness over time and different videos of the found features is analyzed, in particular if they are located in the same part of the eye even when it is moving or after a blink happens. To evaluate over time, sparse optical flow is used to track the found features. Data is provided by mindQ from the project eyeTrax, comprising 20 videos of 10 participants (one video per eye), which were doing multiple, simple tasks in virtual reality in about 5 minutes.


\end{document}