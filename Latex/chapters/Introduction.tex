\documentclass[Bachelorarbeit.tex]{subfiles}
\begin{document}

\newpage
\section{Introduction}
\label{Introduction}
In this thesis, groundwork is acquired for accurate eye-movement classification. The focus lays on improving a medical application, precisely the project eyeTrax by \cite{eyeTrax}, in which the analysis of eye-movement is extracted to yield information of a person's possible malfunctions in oculomotor movement. These malfunctions are indicators of various impairments of the human brain. So far, data is gathered by filming both eyes of a subject via two cameras built inside virtual reality (VR) glasses. This setup is built by adding the Pupil Labs Binocular Addon (Pupil Labs, Berlin) to Vive (HTC and Valve) VR glasses. The subjects complete minor visual tasks and by using the algorithms provided by Pupil Labs' eye-tracker, a classification of eye-movements is obtained.
\\ Eye-tracking is a large field, and various models and implementations exist. Extensive testing was done for example by \cite{holmqvist2017common} for 12 eye-trackers. In particular, the Pupil Labs eye-tracker was tested by \cite{ehinger2019new}. Both studies show, that eye-trackers are not as accurate as one would wish for. Two major problems arise in these papers, one being the loss of accuracy concerning some changes in circumstances, as differing eye-color, the wearing of mascara or even the body-size \citep[pp. 19]{holmqvist2017common}, which imposes problems for this application, where all types of people must be treated equally for a medical diagnosis. The other problem poses the categorization of blinks \citep[p. 6]{ehinger2019new}, which relies on absence of an fitting ellipsis for the tracked pupil in the Pupil Labs eye-tracker does not detect blinks sufficiently, so they could not even use it for their comparison. Other algorithms exist for blink detection, as was summarized by \cite[pp. 2-4]{fogelton2016eye}. Similar to their algorithm, this thesis will lay the ground work to an analysis for eye-movement classification. By calculating Lucas-Kanade optical flow information about movement in videos can be extracted \citep{lucas1981iterative}. In addition to a series of computer vision algorithms it can possibly yield a system to classify eye movement as accurate as is expected for the appliance of medical diagnosis. 
\\ For the purpose of developing a system of algorithms that extract robust motion data from the videos taken by head-mounted eye-trackers, three key point detection algorithms, their parameters, preprocessing steps and parameters for optical flow are tested. This thesis will introduce optical flow in general and in particular the Lucas-Kanade method. Following is an introduction to key point detection and the three detectors in comparison will be explained. Furthermore, how comparison takes place and what is being tested will be shown. Lastly, results will be presented and discussed.

% 12 trackers problems with variation in data(eyecolor, eyeshadow)
% movement in whole video --> world parameter change 

\FloatBarrier
\end{document}